{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"../communication/\" + dataFile\n",
    "    labelFile = \"../communication/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    mytable = assign_label(myOrig)\n",
    "    return mytable\n",
    "\n",
    "\n",
    "def assign_label(data):\n",
    "    c_4 = [1,-1]\n",
    "    c_16 = [3,1,-1,-3]\n",
    "    c_16r = [-3,-1,1,3]\n",
    "    cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "    cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "    cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "    cons4 = data[data.cons==1]\n",
    "    cons4_label = np.array([[cons_4[i-1]]for i in cons4.label])\n",
    "    cons16 = data[data.cons==2]\n",
    "    cons16_label = np.array([[cons_16[i-1]]for i in cons16.label.to_numpy().real.astype(int)])\n",
    "    data[data.cons==2].index\n",
    "    data['buffer'] = 0\n",
    "    data['buffer'] = 0\n",
    "    data.iloc[data[data.cons==1].index, 5] = cons4_label\n",
    "    data.iloc[data[data.cons==2].index, 5] = cons16_label\n",
    "    data['label_real'] = data.buffer.to_numpy().real\n",
    "    data['label_imag'] = data.buffer.to_numpy().imag\n",
    "    myTest = data.copy()\n",
    "    myTest.loc[myTest.cons == 2, 'label'] = myTest.loc[myTest.cons == 2, 'label'] + 4\n",
    "    myTest.label = myTest.label - 1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size, )\n",
    "    cons_array = np.array([[cons[i]] * my_data.shape[0] for i in range(0, block)]).reshape(my_data_size, )\n",
    "    block_array = np.array([([i + 1] * my_data.shape[0]) for i in range(0, block)]).reshape(my_data_size, )\n",
    "    label_array = label.T.reshape(my_data_size, )    \n",
    "    test_pd = pd.DataFrame({'real': my_data_div.real, 'imag': my_data_div.imag,\n",
    "                            'cons': cons_array, 'block': block_array,\n",
    "                            'label': label_array})\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = \"hard\"\n",
    "data1_label = \"hard_label\"\n",
    "data = dataset(data1, data1_label)\n",
    "test = data.loc[:, ('real', 'imag')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(50, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s = make_generator()\n",
    "generator_n = make_generator()\n",
    "generator_i = make_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.Dense(50, activation = 'sigmoid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "discriminator_t = make_discriminator_model()\n",
    "discriminator_d = make_discriminator_model()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "def identity_loss(real, fake):\n",
    "    loss = tf.reduce_mean(tf.abs(real - fake))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_n_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_i_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_t_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(total, label):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        s = generator_s(total, training=True)\n",
    "        n = generator_n(total, training=True)\n",
    "        i = generator_i(total, training=True)\n",
    "        gen = (s + n + i)\n",
    "        gen = tf.reshape(gen, (1,50,2))\n",
    "        fake_t = discriminator_t(gen, training=True)\n",
    "        real_t = discriminator_t(total, training=True)\n",
    "        gen_loss = generator_loss(gen)\n",
    "        fake_d = discriminator_d(s, training=True)\n",
    "        real_d = discriminator_d(label, training=True)\n",
    "        disc_t_loss = discriminator_loss(real_t, fake_t)\n",
    "        disc_d_loss = discriminator_loss(real_d, fake_d)\n",
    "        identity_s_loss = identity_loss(label, s)\n",
    "        identity_g_loss = identity_loss(total, gen)\n",
    "        total_s_loss = 0.2*(gen_loss+identity_g_loss) + 0.8*(identity_s_loss)\n",
    "        total_n_loss = identity_g_loss + gen_loss\n",
    "        total_i_loss = identity_g_loss + gen_loss\n",
    "\n",
    "    gradients_of_s_generator = tape.gradient(total_s_loss, generator_s.trainable_variables)\n",
    "    gradients_of_i_generator = tape.gradient(total_i_loss, generator_i.trainable_variables)\n",
    "    gradients_of_n_generator = tape.gradient(total_n_loss, generator_n.trainable_variables)\n",
    "    gradients_of_discriminator_t = tape.gradient(disc_t_loss, discriminator_t.trainable_variables)\n",
    "    gradients_of_discriminator_d = tape.gradient(disc_d_loss, discriminator_d.trainable_variables)\n",
    "    generator_s_optimizer.apply_gradients(zip(gradients_of_s_generator, generator_s.trainable_variables))\n",
    "    generator_i_optimizer.apply_gradients(zip(gradients_of_i_generator, generator_i.trainable_variables))\n",
    "    generator_n_optimizer.apply_gradients(zip(gradients_of_n_generator, generator_n.trainable_variables))\n",
    "    discriminator_t_optimizer.apply_gradients(zip(gradients_of_discriminator_t, discriminator_t.trainable_variables))\n",
    "    discriminator_d_optimizer.apply_gradients(zip(gradients_of_discriminator_d, discriminator_d.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(my_table):\n",
    "    real_y = (2*my_table.real.min())/(my_table.real.max() - my_table.real.min()) + 1\n",
    "    real_x = (my_table.real.max()) / (1 + real_y)\n",
    "    imag_y = (2*my_table.imag.min())/(my_table.imag.max() - my_table.imag.min()) + 1\n",
    "    imag_x = (my_table.imag.max()) / (1 + imag_y)\n",
    "    my_table.real = (my_table.real / real_x) - real_y\n",
    "    my_table.imag = (my_table.imag/ imag_x) - imag_y\n",
    "    train_feature = data.loc[:, ('real', 'imag')]\n",
    "    train_label = data.loc[:, ('label_real', 'label_imag')]\n",
    "    test_feature = tf.cast(train_feature, tf.float32)\n",
    "    test_label = tf.cast(train_label, tf.float32)\n",
    "    test_feature = tf.reshape(test_feature,(1000,1,50,2))\n",
    "    test_label = tf.reshape(test_label, (1000,1,50,2))\n",
    "    symbol = data.loc[:, 'label']\n",
    "    return test_feature, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l = shuffle_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.20871271]], dtype=float32)>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_t(tf.reshape(generator_s(f[0]), (1,50,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.39248267]], dtype=float32)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_t(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....Time taken for epoch 5 is 0.9467928409576416 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.026924517, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7830434, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 10 is 0.9386239051818848 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.017396772, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.769917, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 15 is 0.9241838455200195 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.016121972, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7655833, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 20 is 0.9161090850830078 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.018865064, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7654552, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 25 is 0.9097471237182617 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.0238522, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7651, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 30 is 0.9362008571624756 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.030152248, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7636156, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 35 is 0.9301540851593018 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.015063268, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7651408, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 40 is 0.9185268878936768 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.020757467, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7643094, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 45 is 0.9897849559783936 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.027270477, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.7626257, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n",
      ".....Time taken for epoch 50 is 0.9256100654602051 sec\n",
      "\n",
      "_____Test Result:_____\n",
      "The generator total loss is tf.Tensor(0.020171605, shape=(), dtype=float32)\n",
      "The signal loss is  tf.Tensor(3.763014, shape=(), dtype=float32)\n",
      "___________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for i in range(len(f)):\n",
    "        test = f[i]\n",
    "        label = l[i]\n",
    "        train_step(test, label)\n",
    "        if n % 10 == 0:\n",
    "            print ('.', end='')\n",
    "            n+=1\n",
    "        \n",
    "    if  ((epoch+1)%5) == 0:\n",
    "        print('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                           time.time() - start))\n",
    "    if  ((epoch+1)%5) == 0:\n",
    "        id = str(epoch)\n",
    "        s = generator_s(test_feature, training=False)\n",
    "        i = generator_i(test_feature, training=False)\n",
    "        n = generator_n(test_feature, training=False)\n",
    "        gen = s + i + n\n",
    "        test = identity_loss(s, test_label)\n",
    "        gen_loss = identity_loss(gen, test_feature)\n",
    "        print(\"_____Test Result:_____\")\n",
    "        print('The generator total loss is', gen_loss)\n",
    "        print('The signal loss is ', test)\n",
    "        print(\"___________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[ 0.9486833 , -0.31622776],\n",
       "       [ 0.31622776, -0.9486833 ],\n",
       "       [ 0.9486833 ,  0.9486833 ],\n",
       "       [ 0.31622776,  0.9486833 ],\n",
       "       [ 0.9486833 ,  0.9486833 ],\n",
       "       [-0.31622776,  0.31622776],\n",
       "       [-0.9486833 ,  0.31622776],\n",
       "       [ 0.31622776, -0.9486833 ],\n",
       "       [-0.9486833 ,  0.9486833 ],\n",
       "       [-0.31622776, -0.31622776]], dtype=float32)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
