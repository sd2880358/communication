{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdcd94c90f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.00113796]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-b5acd5b90135>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Produce images for the GIF as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in train_dataset:\n",
    "    generated_images = generator(noise, training=True)\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in train_dataset:\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(100, 12544), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(12544,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(12544,), dtype=float32, numpy=\n",
       " array([-1.0643476e-03, -3.6573975e-04,  2.0060247e-04, ...,\n",
       "         4.7925831e-05, -5.2447611e-04,  2.4212798e-04], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 5, 128, 256), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 1.1625117e-04, -5.0032081e-04,  1.3882747e-03, -5.6119624e-04,\n",
       "        -2.1205961e-03,  9.7184215e-04, -1.0026196e-03, -4.1369884e-04,\n",
       "         1.4214910e-03,  2.3660839e-04, -3.6718398e-03, -1.2155031e-03,\n",
       "         5.2813429e-04,  6.2773837e-04,  1.8855534e-04,  7.6025882e-04,\n",
       "        -4.0221869e-04, -1.2874410e-03,  9.6103267e-06, -9.9029101e-04,\n",
       "         3.6822684e-04, -1.1583457e-03, -7.9083181e-04,  3.7008041e-04,\n",
       "         6.5817832e-05, -2.9932186e-03, -1.2385828e-03, -1.6367713e-03,\n",
       "        -1.8073015e-03,  1.3997160e-03, -2.4857081e-03, -1.2995151e-03,\n",
       "         5.6464312e-05, -1.5167487e-03, -1.1442705e-03, -3.5524231e-04,\n",
       "         9.7546005e-04,  2.0823683e-04,  8.6775282e-04,  2.6965444e-04,\n",
       "        -7.4425043e-06, -2.4277866e-03,  1.3648410e-03, -6.2972843e-04,\n",
       "         7.5576530e-04, -2.7275796e-03,  1.1916712e-03, -1.5307273e-03,\n",
       "         3.7255825e-04,  2.2777759e-04,  4.4995460e-05,  8.3071040e-04,\n",
       "         3.1096075e-04, -1.8181934e-03,  8.2203955e-04, -5.3494197e-04,\n",
       "        -5.3656724e-04,  1.2604304e-03,  4.0563667e-04, -9.5654005e-04,\n",
       "        -5.5649440e-04, -1.4356327e-03, -5.6892814e-04, -1.6902646e-05,\n",
       "         2.4297873e-03, -4.4417917e-05,  1.7690824e-03, -1.1193613e-03,\n",
       "        -1.7868352e-04, -4.7052742e-04, -6.2637177e-05, -2.5573589e-03,\n",
       "        -1.4873589e-03,  1.5162997e-03, -1.5101283e-03,  6.6196662e-04,\n",
       "         3.4922748e-04, -1.0123562e-04, -1.8832254e-03, -8.8911562e-04,\n",
       "        -2.8580627e-03, -1.3546895e-03, -9.1245980e-04,  1.7836955e-03,\n",
       "        -8.7947823e-04,  1.6832832e-04, -1.0818749e-05, -5.1301811e-04,\n",
       "        -3.2385270e-04, -1.5181599e-03, -8.3043799e-04,  9.9582446e-04,\n",
       "         1.4702962e-03, -2.6257872e-03, -5.6990009e-04, -1.0240307e-04,\n",
       "         2.9978351e-04,  2.8277995e-04, -3.1962574e-03,  3.5482092e-04,\n",
       "         5.1836990e-04,  2.5488082e-03,  4.3147558e-04,  5.4800196e-04,\n",
       "         1.9749720e-04, -6.7646545e-04,  1.2178933e-03,  1.3168768e-03,\n",
       "         8.1198092e-04,  7.2925427e-04, -1.7192449e-03,  2.1383057e-03,\n",
       "        -7.7294995e-04,  9.3705696e-04,  1.2699577e-03, -2.3281842e-03,\n",
       "        -3.8869143e-04,  2.9134809e-04,  8.7202492e-04,  6.1618804e-04,\n",
       "        -7.5654074e-04,  9.6386933e-04, -6.3088036e-04, -1.4783407e-05,\n",
       "        -2.1365059e-03,  4.0857345e-04,  1.2249072e-03, -5.6317350e-04],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 5, 64, 128), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([ 5.73271755e-05, -7.13869158e-05,  1.26253799e-04, -4.07095504e-04,\n",
       "         6.69260844e-05, -1.81720388e-04, -5.83107758e-04,  8.61014123e-05,\n",
       "        -2.00113107e-04, -6.49171398e-06, -3.53147858e-04,  3.51276831e-04,\n",
       "        -4.23586491e-04,  4.54435271e-04,  4.22623300e-04,  7.03941405e-05,\n",
       "         6.29263668e-05, -2.53590872e-04, -6.02849002e-04, -1.41002820e-04,\n",
       "         8.89746007e-05,  3.51101407e-05,  2.12944855e-04, -3.27118847e-04,\n",
       "         1.74081142e-04,  7.05997110e-04,  5.29073659e-05, -3.26971611e-04,\n",
       "        -4.15464427e-04, -3.87962529e-04, -5.58680098e-04,  9.98915493e-05,\n",
       "        -3.22895212e-04, -5.77687228e-04,  1.06868378e-04, -4.81005234e-04,\n",
       "        -4.59711649e-04, -7.17635849e-05,  5.51985460e-04,  3.53639742e-04,\n",
       "        -1.48224790e-04,  3.74218325e-05, -6.28376220e-05, -6.59827201e-04,\n",
       "        -1.45598664e-04,  7.10005188e-05, -4.02415521e-04, -2.96063838e-04,\n",
       "         2.31593294e-04, -4.10397624e-05, -1.19577795e-04,  9.64426319e-04,\n",
       "        -1.83941433e-04,  6.42400468e-04, -8.11065183e-05,  1.21002711e-04,\n",
       "         3.72020993e-04,  1.30779808e-04,  1.76652597e-04, -1.70967731e-04,\n",
       "        -5.37736632e-04,  4.62528405e-04,  2.22833056e-04,  2.87982344e-04],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 5, 1, 64), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_of_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
