{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa537e11160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00201863]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-b5acd5b90135>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Produce images for the GIF as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
