{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678+0.70710678j  0.70710678-0.70710678j -0.70710678+0.70710678j\n",
      " -0.70710678-0.70710678j] \n",
      " [-0.9486833 +0.9486833j  -0.31622777+0.9486833j   0.31622777+0.9486833j\n",
      "  0.9486833 +0.9486833j  -0.9486833 +0.31622777j -0.31622777+0.31622777j\n",
      "  0.31622777+0.31622777j  0.9486833 +0.31622777j -0.9486833 -0.31622777j\n",
      " -0.31622777-0.31622777j  0.31622777-0.31622777j  0.9486833 -0.31622777j\n",
      " -0.9486833 -0.9486833j  -0.31622777-0.9486833j   0.31622777-0.9486833j\n",
      "  0.9486833 -0.9486833j ]\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "print(cons_4,\"\\n\",cons_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"./communication/\" + dataFile\n",
    "    labelFile = \"./communication/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    mytable = assign_label(myOrig)\n",
    "    return mytable\n",
    "\n",
    "\n",
    "def assign_label(data):\n",
    "    c_4 = [1,-1]\n",
    "    c_16 = [3,1,-1,-3]\n",
    "    c_16r = [-3,-1,1,3]\n",
    "    cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "    cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "    cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "    cons4 = data[data.cons==1]\n",
    "    cons4_label = np.array([[cons_4[i-1]]for i in cons4.label])\n",
    "    cons16 = data[data.cons==2]\n",
    "    cons16_label = np.array([[cons_16[i-1]]for i in cons16.label.to_numpy().real.astype(int)])\n",
    "    data[data.cons==2].index\n",
    "    data['buffer'] = 0\n",
    "    data['buffer'] = 0\n",
    "    data.iloc[data[data.cons==1].index, 5] = cons4_label\n",
    "    data.iloc[data[data.cons==2].index, 5] = cons16_label\n",
    "    data['label_real'] = data.buffer.to_numpy().real\n",
    "    data['label_imag'] = data.buffer.to_numpy().imag\n",
    "    myTest = data.copy()\n",
    "    myTest.loc[myTest.cons == 2, 'label'] = myTest.loc[myTest.cons == 2, 'label'] + 4\n",
    "    myTest.label = myTest.label - 1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size, )\n",
    "    cons_array = np.array([[cons[i]] * my_data.shape[0] for i in range(0, block)]).reshape(my_data_size, )\n",
    "    block_array = np.array([([i + 1] * my_data.shape[0]) for i in range(0, block)]).reshape(my_data_size, )\n",
    "    label_array = label.T.reshape(my_data_size, )    \n",
    "    test_pd = pd.DataFrame({'real': my_data_div.real, 'imag': my_data_div.imag,\n",
    "                            'cons': cons_array, 'block': block_array,\n",
    "                            'label': label_array})\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>imag</th>\n",
       "      <th>cons</th>\n",
       "      <th>block</th>\n",
       "      <th>label</th>\n",
       "      <th>buffer</th>\n",
       "      <th>label_real</th>\n",
       "      <th>label_imag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.806980</td>\n",
       "      <td>-13.804771</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.948683-0.316228j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-21.419588</td>\n",
       "      <td>-58.747407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.033908</td>\n",
       "      <td>40.251547</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.948683+0.948683j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.841522</td>\n",
       "      <td>72.678677</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316228+0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.576088</td>\n",
       "      <td>67.132076</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.948683+0.948683j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>28.789324</td>\n",
       "      <td>-41.060747</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>28.106421</td>\n",
       "      <td>-54.533358</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>-19.969952</td>\n",
       "      <td>-39.392252</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.316228-0.316228j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-14.243322</td>\n",
       "      <td>5.572663</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.316228-0.316228j</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>33.826814</td>\n",
       "      <td>41.404952</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316228+0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            real       imag  cons  block  label              buffer  \\\n",
       "0      48.806980 -13.804771     2      1     15  0.948683-0.316228j   \n",
       "1     -21.419588 -58.747407     2      1     18  0.316228-0.948683j   \n",
       "2      61.033908  40.251547     2      1      7  0.948683+0.948683j   \n",
       "3      25.841522  72.678677     2      1      6  0.316228+0.948683j   \n",
       "4      40.576088  67.132076     2      1      7  0.948683+0.948683j   \n",
       "...          ...        ...   ...    ...    ...                 ...   \n",
       "49995  28.789324 -41.060747     2   1000     18  0.316228-0.948683j   \n",
       "49996  28.106421 -54.533358     2   1000     18  0.316228-0.948683j   \n",
       "49997 -19.969952 -39.392252     2   1000     14  0.316228-0.316228j   \n",
       "49998 -14.243322   5.572663     2   1000     13 -0.316228-0.316228j   \n",
       "49999  33.826814  41.404952     2   1000      6  0.316228+0.948683j   \n",
       "\n",
       "       label_real  label_imag  \n",
       "0        0.948683   -0.316228  \n",
       "1        0.316228   -0.948683  \n",
       "2        0.948683    0.948683  \n",
       "3        0.316228    0.948683  \n",
       "4        0.948683    0.948683  \n",
       "...           ...         ...  \n",
       "49995    0.316228   -0.948683  \n",
       "49996    0.316228   -0.948683  \n",
       "49997    0.316228   -0.316228  \n",
       "49998   -0.316228   -0.316228  \n",
       "49999    0.316228    0.948683  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = \"hard\"\n",
    "data1_label = \"hard_label\"\n",
    "data = dataset(data1, data1_label)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[2,]))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_n = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_i = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[2,]))\n",
    "    model.add(layers.Dense(50, activation = 'sigmoid'))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_t = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_d = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(real, fake):\n",
    "    loss = tf.reduce_mean(tf.abs(real - fake))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_n_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_i_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_t_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/dis\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_s=generator_s,\n",
    "                           generator_n=generator_n,\n",
    "                           generator_i=generator_i,\n",
    "                           discriminator_t=discriminator_t,\n",
    "                           discriminator_d=discriminator_d,\n",
    "                           generator_s_optimizer=generator_s_optimizer,\n",
    "                           generator_n_optimizer=generator_n_optimizer,\n",
    "                           generator_i_optimizer=generator_i_optimizer,\n",
    "                           discriminator_d_optimizer=discriminator_d_optimizer,\n",
    "                           discriminator_t_optimizer=discriminator_t_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b053243d9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(total, label):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        s = generator_s(total, training=True)\n",
    "        n = generator_n(total, training=True)\n",
    "        i = generator_i(total, training=True)\n",
    "        gen = s + n + i\n",
    "        fake_t = discriminator_t(gen, training=True)\n",
    "        real_t = discriminator_t(total, training=True)\n",
    "        fake_d = discriminator_d(s, training=True)\n",
    "        real_d = discriminator_d(label, training=True)\n",
    "        s_loss = generator_loss(s)\n",
    "        n_loss = generator_loss(n)\n",
    "        i_loss = generator_loss(i)\n",
    "        disc_t_loss = discriminator_loss(real_t, fake_t)\n",
    "        disc_d_loss = discriminator_loss(real_d, fake_d)\n",
    "        identity_s_loss = identity_loss(label, s)\n",
    "        identity_g_loss = identity_loss(total, gen)\n",
    "        total_s_loss = 0.5 * (identity_s_loss + s_loss) + 0.5 * (identity_g_loss)\n",
    "        total_n_loss = identity_g_loss + n_loss\n",
    "        total_i_loss = identity_g_loss + i_loss\n",
    "        print()\n",
    "        \n",
    "    gradients_of_s_generator = tape.gradient(total_s_loss, generator_s.trainable_variables)\n",
    "    gradients_of_i_generator = tape.gradient(total_i_loss, generator_i.trainable_variables)\n",
    "    gradients_of_n_generator = tape.gradient(total_n_loss, generator_n.trainable_variables)\n",
    "    gradients_of_discriminator_t = tape.gradient(disc_t_loss, discriminator_t.trainable_variables)\n",
    "    gradients_of_discriminator_d = tape.gradient(disc_d_loss, discriminator_d.trainable_variables)\n",
    "    generator_s_optimizer.apply_gradients(zip(gradients_of_s_generator, generator_s.trainable_variables))\n",
    "    generator_i_optimizer.apply_gradients(zip(gradients_of_i_generator, generator_i.trainable_variables))\n",
    "    generator_n_optimizer.apply_gradients(zip(gradients_of_n_generator, generator_n.trainable_variables))\n",
    "    discriminator_t_optimizer.apply_gradients(zip(gradients_of_discriminator_t, discriminator_t.trainable_variables))\n",
    "    discriminator_d_optimizer.apply_gradients(zip(gradients_of_discriminator_d, discriminator_d.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = data.loc[:,('real', 'imag')]\n",
    "train_label = data.loc[:, ('label_real', 'label_imag')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = tf.cast(train_feature, tf.float32)\n",
    "test_label = tf.cast(train_label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....."
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for i in range(len(test_feature)):\n",
    "        test = tf.reshape(test_feature[i], [1,2])\n",
    "        label = tf.reshape(test_label[i], [1,2])\n",
    "        train_step(test, label)\n",
    "        if n % 10 == 0:\n",
    "            print ('.', end='')\n",
    "            n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generator_s(test_feature, training=False)\n",
    "i = generator_i(test_feature, training=False)\n",
    "n = generator_n(test_feature, training=False)\n",
    "gen = s + i + n\n",
    "test = np.array([(test_feature - gen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([s - test_label]).mean()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, input_h\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(20)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50000, 2), dtype=float32, numpy=\n",
       "array([[ 0.74356425, -0.39451778],\n",
       "       [-0.63942367, -0.6913041 ],\n",
       "       [ 0.69628894,  0.9595338 ],\n",
       "       ...,\n",
       "       [-0.59323114, -0.5585426 ],\n",
       "       [-0.6560704 ,  0.2876377 ],\n",
       "       [ 0.56631446,  0.91844213]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_s(train_feature.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = real.size\n",
    "real = np.array([s[:, 0]]).reshape(size)\n",
    "imag = np.array([s[:, 1]]).reshape(size)\n",
    "mlcData = pd.DataFrame({'real':real, 'imag':imag.T, 'label':symbol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"../ML_Symbol_Gen-main/\" + dataFile\n",
    "    labelFile = \"../ML_Symbol_Gen-main/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    mytable = assign_label(myOrig)\n",
    "    return mytable\n",
    "\n",
    "\n",
    "def assign_label(data):\n",
    "    c_4 = [1,-1]\n",
    "    c_16 = [3,1,-1,-3]\n",
    "    c_16r = [-3,-1,1,3]\n",
    "    cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "    cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "    cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "    cons4 = data[data.cons==1]\n",
    "    cons4_label = np.array([[cons_4[i-1]]for i in cons4.label])\n",
    "    cons16 = data[data.cons==2]\n",
    "    cons16_label = np.array([[cons_16[i-1]]for i in cons16.label.to_numpy().real.astype(int)])\n",
    "    data[data.cons==2].index\n",
    "    data['buffer'] = 0\n",
    "    data['buffer'] = 0\n",
    "    data.iloc[data[data.cons==1].index, 5] = cons4_label\n",
    "    data.iloc[data[data.cons==2].index, 5] = cons16_label\n",
    "    data['label_real'] = data.buffer.to_numpy().real\n",
    "    data['label_imag'] = data.buffer.to_numpy().imag\n",
    "    myTest = data.copy()\n",
    "    myTest.loc[myTest.cons == 2, 'label'] = myTest.loc[myTest.cons == 2, 'label'] + 4\n",
    "    myTest.label = myTest.label - 1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size, )\n",
    "    cons_array = np.array([[cons[i]] * my_data.shape[0] for i in range(0, block)]).reshape(my_data_size, )\n",
    "    block_array = np.array([([i + 1] * my_data.shape[0]) for i in range(0, block)]).reshape(my_data_size, )\n",
    "    label_array = label.T.reshape(my_data_size, )\n",
    "    test_pd = pd.DataFrame({'real': my_data_div.real, 'imag': my_data_div.imag,\n",
    "                            'cons': cons_array, 'block': block_array,\n",
    "                            'label': label_array})\n",
    "    return test_pd\n",
    "\n",
    "def make_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation = 'sigmoid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def identity_loss(real, fake):\n",
    "    loss = tf.reduce_mean(tf.abs(real - fake))\n",
    "    return LAMBDA * 0.5 * loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(total, label):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        s = generator_s(total, training=True)\n",
    "        n = generator_n(total, training=True)\n",
    "        i = generator_i(total, training=True)\n",
    "        gen = (s + n + i)\n",
    "        gen = tf.reshape(gen, (1,50,2))\n",
    "        fake_t = discriminator_t(gen, training=True)\n",
    "        real_t = discriminator_t(total, training=True)\n",
    "        fake_d = discriminator_d(s, training=True)\n",
    "        real_d = discriminator_d(label, training=True)\n",
    "        gen_global_loss = generator_loss(fake_d)\n",
    "        gen_local_loss = generator_loss(fake_d)\n",
    "        gen_total_loss = 1/2 * gen_local_loss + gen_global_loss\n",
    "        disc_t_loss = discriminator_loss(real_t, fake_t)\n",
    "        disc_d_loss = discriminator_loss(real_d, fake_d)\n",
    "        identity_s_loss = identity_loss(label, s)\n",
    "        identity_g_loss = identity_loss(total, gen)\n",
    "        total_s_loss = identity_g_loss + 1/2* identity_s_loss + gen_total_loss\n",
    "        total_n_loss = identity_g_loss + gen_total_loss\n",
    "        total_i_loss = identity_g_loss + gen_total_loss\n",
    "\n",
    "    gradients_of_s_generator = tape.gradient(total_s_loss, generator_s.trainable_variables)\n",
    "    gradients_of_i_generator = tape.gradient(total_i_loss, generator_i.trainable_variables)\n",
    "    gradients_of_n_generator = tape.gradient(total_n_loss, generator_n.trainable_variables)\n",
    "    gradients_of_discriminator_t = tape.gradient(disc_t_loss, discriminator_t.trainable_variables)\n",
    "    gradients_of_discriminator_d = tape.gradient(disc_d_loss, discriminator_d.trainable_variables)\n",
    "    generator_s_optimizer.apply_gradients(zip(gradients_of_s_generator, generator_s.trainable_variables))\n",
    "    generator_i_optimizer.apply_gradients(zip(gradients_of_i_generator, generator_i.trainable_variables))\n",
    "    generator_n_optimizer.apply_gradients(zip(gradients_of_n_generator, generator_n.trainable_variables))\n",
    "    discriminator_t_optimizer.apply_gradients(zip(gradients_of_discriminator_t, discriminator_t.trainable_variables))\n",
    "    discriminator_d_optimizer.apply_gradients(zip(gradients_of_discriminator_d, discriminator_d.trainable_variables))\n",
    "\n",
    "def shuffle_data(my_table):\n",
    "\n",
    "    '''\n",
    "    real_y = (2*my_table.real.min())/(my_table.real.max() - my_table.real.min()) + 1\n",
    "    real_x = (my_table.real.max()) / (1 + real_y)\n",
    "    imag_y = (2*my_table.imag.min())/(my_table.imag.max() - my_table.imag.min()) + 1\n",
    "    imag_x = (my_table.imag.max()) / (1 + imag_y)\n",
    "    my_table.real = (my_table.real / real_x) - real_y\n",
    "    my_table.imag = (my_table.imag/ imag_x) - imag_y\n",
    "    '''\n",
    "    train_feature = data.loc[:, ('real', 'imag')]\n",
    "    train_label = data.loc[:, ('label_real', 'label_imag')]\n",
    "    test_feature = tf.cast(train_feature, tf.float32)\n",
    "    test_label = tf.cast(train_label, tf.float32)\n",
    "    test_feature = tf.reshape(test_feature,(1000,1,50,2))\n",
    "    test_label = tf.reshape(test_label, (1000,1,50,2))\n",
    "    symbol = data.loc[:, 'label']\n",
    "    return test_feature, test_label\n",
    "\n",
    "generator_s = make_generator()\n",
    "generator_n = make_generator()\n",
    "generator_i = make_generator()\n",
    "discriminator_t = make_discriminator_model()\n",
    "discriminator_d = make_discriminator_model()\n",
    "\n",
    "\n",
    "generator_s_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_n_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_i_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_t_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/method4\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_s=generator_s,\n",
    "                           generator_n=generator_n,\n",
    "                           generator_i=generator_i,\n",
    "                           discriminator_t=discriminator_t,\n",
    "                           discriminator_d=discriminator_d,\n",
    "                           generator_s_optimizer=generator_s_optimizer,\n",
    "                           generator_n_optimizer=generator_n_optimizer,\n",
    "                           generator_i_optimizer=generator_i_optimizer,\n",
    "                           discriminator_d_optimizer=discriminator_d_optimizer,\n",
    "                           discriminator_t_optimizer=discriminator_t_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "\n",
    "LAMBDA = 10\n",
    "EPOCHS = 500\n",
    "data1 = \"my_data\"\n",
    "data1_label = \"my_labels\"\n",
    "data = dataset(data1, data1_label)\n",
    "file_directory = './result/tes2/'\n",
    "f, l = shuffle_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = generator_i(f, training=False)\n",
    "n = generator_n(f, training=False)\n",
    "s = generator_s(f, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 1, 50, 2), dtype=float32, numpy=\n",
       "array([[[[ 6.5048331e-01, -4.7139320e-01],\n",
       "         [ 5.0203842e-01, -4.2866489e-01],\n",
       "         [-1.8202192e-01, -5.1785016e-01],\n",
       "         ...,\n",
       "         [ 4.2427875e-02,  1.1653598e-01],\n",
       "         [-3.2738814e-01, -4.2376378e-01],\n",
       "         [-1.1968143e-01, -8.7568581e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.3305618e+00,  1.4334658e-01],\n",
       "         [-7.4759483e-02, -8.7472051e-04],\n",
       "         [-9.6479855e-02, -7.8648165e-02],\n",
       "         ...,\n",
       "         [-2.4889690e-01, -9.5817643e-01],\n",
       "         [-2.4754605e-01, -9.5954239e-01],\n",
       "         [ 1.3452172e+00,  1.4299063e-01]]],\n",
       "\n",
       "\n",
       "       [[[-2.9098436e-01, -9.3180442e-01],\n",
       "         [-1.2972951e-01, -4.2063218e-02],\n",
       "         [-2.0112292e-01, -8.5353583e-01],\n",
       "         ...,\n",
       "         [ 3.4581855e-01, -3.3269733e-01],\n",
       "         [ 7.7228040e-01, -2.0149653e-01],\n",
       "         [ 9.1224229e-01, -8.0747694e-02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 2.1864217e-02, -2.3982510e-01],\n",
       "         [ 1.4550730e+00,  1.7681012e-01],\n",
       "         [ 4.8603567e-01, -3.3485749e-01],\n",
       "         ...,\n",
       "         [ 4.7036223e-02, -1.4582065e-01],\n",
       "         [ 1.0271291e+00,  2.0488568e-01],\n",
       "         [-5.5466443e-01, -6.3630754e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.8678191e-01, -5.0982815e-01],\n",
       "         [ 4.9398944e-01, -3.7078106e-01],\n",
       "         [ 7.6469123e-01, -1.5182222e-01],\n",
       "         ...,\n",
       "         [-1.8895471e-01, -8.3726102e-01],\n",
       "         [-3.7429288e-01, -4.0373200e-01],\n",
       "         [ 3.0926518e-02, -2.3263498e-01]]],\n",
       "\n",
       "\n",
       "       [[[-8.0895044e-02,  5.0554574e-03],\n",
       "         [-1.3689606e-01, -2.1206594e-01],\n",
       "         [-2.3549351e-01, -8.8937300e-01],\n",
       "         ...,\n",
       "         [-1.7133525e-01, -2.6591021e-01],\n",
       "         [-6.9027677e-02, -3.2541443e-02],\n",
       "         [ 1.3731917e+00,  1.6219637e-01]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 1, 50, 2), dtype=float32, numpy=\n",
       "array([[[[ 0.14946973,  0.13284312],\n",
       "         [-0.0825538 ,  0.18186955],\n",
       "         [ 0.67483646, -1.2518511 ],\n",
       "         ...,\n",
       "         [ 0.7656009 , -0.46409792],\n",
       "         [-1.2187556 ,  0.69230765],\n",
       "         [ 0.6425323 , -0.7427203 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.63798714,  0.7266077 ],\n",
       "         [ 0.7271349 , -0.66219974],\n",
       "         [ 0.72692114, -0.77591264],\n",
       "         ...,\n",
       "         [-0.6924323 , -0.7192513 ],\n",
       "         [-0.71012515, -0.7060385 ],\n",
       "         [ 0.66356194,  0.71309155]]],\n",
       "\n",
       "\n",
       "       [[[-0.52561057, -0.895238  ],\n",
       "         [ 0.5617081 , -0.6359891 ],\n",
       "         [-0.62463534, -0.6183672 ],\n",
       "         ...,\n",
       "         [ 0.68960065, -0.15898392],\n",
       "         [-0.04458979,  0.546267  ],\n",
       "         [ 1.3303292 ,  0.06079383]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 1.1064188 , -1.1373672 ],\n",
       "         [ 1.1140479 ,  0.6062598 ],\n",
       "         [ 0.8002203 , -0.09222884],\n",
       "         ...,\n",
       "         [ 1.1040192 , -1.0085149 ],\n",
       "         [-0.09260558,  1.2524233 ],\n",
       "         [ 0.0564349 , -1.2153183 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.6457959 , -1.2319659 ],\n",
       "         [ 0.69341546, -0.0298493 ],\n",
       "         [ 1.172737  , -0.0051464 ],\n",
       "         ...,\n",
       "         [-0.84452444, -0.45910737],\n",
       "         [-1.2426928 ,  1.2016144 ],\n",
       "         [ 1.126994  , -1.1343719 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.702767  , -0.6393632 ],\n",
       "         [ 0.6240649 , -0.87184453],\n",
       "         [-0.5642997 , -0.74632245],\n",
       "         ...,\n",
       "         [-0.69973457,  0.66537684],\n",
       "         [ 0.7786182 , -0.73886275],\n",
       "         [ 0.68716985,  0.7376524 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
