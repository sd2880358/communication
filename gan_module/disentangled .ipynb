{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678+0.70710678j  0.70710678-0.70710678j -0.70710678+0.70710678j\n",
      " -0.70710678-0.70710678j] \n",
      " [-0.9486833 +0.9486833j  -0.31622777+0.9486833j   0.31622777+0.9486833j\n",
      "  0.9486833 +0.9486833j  -0.9486833 +0.31622777j -0.31622777+0.31622777j\n",
      "  0.31622777+0.31622777j  0.9486833 +0.31622777j -0.9486833 -0.31622777j\n",
      " -0.31622777-0.31622777j  0.31622777-0.31622777j  0.9486833 -0.31622777j\n",
      " -0.9486833 -0.9486833j  -0.31622777-0.9486833j   0.31622777-0.9486833j\n",
      "  0.9486833 -0.9486833j ]\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "print(cons_4,\"\\n\",cons_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"./communication/\" + dataFile\n",
    "    labelFile = \"./communication/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    mytable = assign_label(myOrig)\n",
    "    return mytable\n",
    "\n",
    "\n",
    "def assign_label(data):\n",
    "    c_4 = [1,-1]\n",
    "    c_16 = [3,1,-1,-3]\n",
    "    c_16r = [-3,-1,1,3]\n",
    "    cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "    cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "    cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "    cons4 = data[data.cons==1]\n",
    "    cons4_label = np.array([[cons_4[i-1]]for i in cons4.label])\n",
    "    cons16 = data[data.cons==2]\n",
    "    cons16_label = np.array([[cons_16[i-1]]for i in cons16.label.to_numpy().real.astype(int)])\n",
    "    data[data.cons==2].index\n",
    "    data['buffer'] = 0\n",
    "    data['buffer'] = 0\n",
    "    data.iloc[data[data.cons==1].index, 5] = cons4_label\n",
    "    data.iloc[data[data.cons==2].index, 5] = cons16_label\n",
    "    data['label_real'] = data.buffer.to_numpy().real\n",
    "    data['label_imag'] = data.buffer.to_numpy().imag\n",
    "    myTest = data.copy()\n",
    "    myTest.loc[myTest.cons == 2, 'label'] = myTest.loc[myTest.cons == 2, 'label'] + 4\n",
    "    myTest.label = myTest.label - 1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size, )\n",
    "    cons_array = np.array([[cons[i]] * my_data.shape[0] for i in range(0, block)]).reshape(my_data_size, )\n",
    "    block_array = np.array([([i + 1] * my_data.shape[0]) for i in range(0, block)]).reshape(my_data_size, )\n",
    "    label_array = label.T.reshape(my_data_size, )    \n",
    "    test_pd = pd.DataFrame({'real': my_data_div.real, 'imag': my_data_div.imag,\n",
    "                            'cons': cons_array, 'block': block_array,\n",
    "                            'label': label_array})\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>imag</th>\n",
       "      <th>cons</th>\n",
       "      <th>block</th>\n",
       "      <th>label</th>\n",
       "      <th>buffer</th>\n",
       "      <th>label_real</th>\n",
       "      <th>label_imag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.806980</td>\n",
       "      <td>-13.804771</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.948683-0.316228j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-21.419588</td>\n",
       "      <td>-58.747407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.033908</td>\n",
       "      <td>40.251547</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.948683+0.948683j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.841522</td>\n",
       "      <td>72.678677</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316228+0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.576088</td>\n",
       "      <td>67.132076</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.948683+0.948683j</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>28.789324</td>\n",
       "      <td>-41.060747</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>28.106421</td>\n",
       "      <td>-54.533358</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.316228-0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>-19.969952</td>\n",
       "      <td>-39.392252</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.316228-0.316228j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-14.243322</td>\n",
       "      <td>5.572663</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.316228-0.316228j</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>33.826814</td>\n",
       "      <td>41.404952</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316228+0.948683j</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            real       imag  cons  block  label              buffer  \\\n",
       "0      48.806980 -13.804771     2      1     15  0.948683-0.316228j   \n",
       "1     -21.419588 -58.747407     2      1     18  0.316228-0.948683j   \n",
       "2      61.033908  40.251547     2      1      7  0.948683+0.948683j   \n",
       "3      25.841522  72.678677     2      1      6  0.316228+0.948683j   \n",
       "4      40.576088  67.132076     2      1      7  0.948683+0.948683j   \n",
       "...          ...        ...   ...    ...    ...                 ...   \n",
       "49995  28.789324 -41.060747     2   1000     18  0.316228-0.948683j   \n",
       "49996  28.106421 -54.533358     2   1000     18  0.316228-0.948683j   \n",
       "49997 -19.969952 -39.392252     2   1000     14  0.316228-0.316228j   \n",
       "49998 -14.243322   5.572663     2   1000     13 -0.316228-0.316228j   \n",
       "49999  33.826814  41.404952     2   1000      6  0.316228+0.948683j   \n",
       "\n",
       "       label_real  label_imag  \n",
       "0        0.948683   -0.316228  \n",
       "1        0.316228   -0.948683  \n",
       "2        0.948683    0.948683  \n",
       "3        0.316228    0.948683  \n",
       "4        0.948683    0.948683  \n",
       "...           ...         ...  \n",
       "49995    0.316228   -0.948683  \n",
       "49996    0.316228   -0.948683  \n",
       "49997    0.316228   -0.316228  \n",
       "49998   -0.316228   -0.316228  \n",
       "49999    0.316228    0.948683  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = \"hard\"\n",
    "data1_label = \"hard_label\"\n",
    "data = dataset(data1, data1_label)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[2,]))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_n = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_i = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(20, use_bias=False, input_shape=[2,]))\n",
    "    model.add(layers.Dense(50, activation = 'sigmoid'))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_t = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_d = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(real, fake):\n",
    "    loss = tf.reduce_mean(tf.abs(real - fake))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_s_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_n_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_i_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_t_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/dis\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_s=generator_s,\n",
    "                           generator_n=generator_n,\n",
    "                           generator_i=generator_i,\n",
    "                           discriminator_t=discriminator_t,\n",
    "                           discriminator_d=discriminator_d,\n",
    "                           generator_s_optimizer=generator_s_optimizer,\n",
    "                           generator_n_optimizer=generator_n_optimizer,\n",
    "                           generator_i_optimizer=generator_i_optimizer,\n",
    "                           discriminator_d_optimizer=discriminator_d_optimizer,\n",
    "                           discriminator_t_optimizer=discriminator_t_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b053243d9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(total, label):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        s = generator_s(total, training=True)\n",
    "        n = generator_n(total, training=True)\n",
    "        i = generator_i(total, training=True)\n",
    "        gen = s + n + i\n",
    "        fake_t = discriminator_t(gen, training=True)\n",
    "        real_t = discriminator_t(total, training=True)\n",
    "        fake_d = discriminator_d(s, training=True)\n",
    "        real_d = discriminator_d(label, training=True)\n",
    "        s_loss = generator_loss(s)\n",
    "        n_loss = generator_loss(n)\n",
    "        i_loss = generator_loss(i)\n",
    "        disc_t_loss = discriminator_loss(real_t, fake_t)\n",
    "        disc_d_loss = discriminator_loss(real_d, fake_d)\n",
    "        identity_s_loss = identity_loss(label, s)\n",
    "        identity_g_loss = identity_loss(total, gen)\n",
    "        total_s_loss = 0.5 * (identity_s_loss + s_loss) + 0.5 * (identity_g_loss)\n",
    "        total_n_loss = identity_g_loss + n_loss\n",
    "        total_i_loss = identity_g_loss + i_loss\n",
    "        print()\n",
    "        \n",
    "    gradients_of_s_generator = tape.gradient(total_s_loss, generator_s.trainable_variables)\n",
    "    gradients_of_i_generator = tape.gradient(total_i_loss, generator_i.trainable_variables)\n",
    "    gradients_of_n_generator = tape.gradient(total_n_loss, generator_n.trainable_variables)\n",
    "    gradients_of_discriminator_t = tape.gradient(disc_t_loss, discriminator_t.trainable_variables)\n",
    "    gradients_of_discriminator_d = tape.gradient(disc_d_loss, discriminator_d.trainable_variables)\n",
    "    generator_s_optimizer.apply_gradients(zip(gradients_of_s_generator, generator_s.trainable_variables))\n",
    "    generator_i_optimizer.apply_gradients(zip(gradients_of_i_generator, generator_i.trainable_variables))\n",
    "    generator_n_optimizer.apply_gradients(zip(gradients_of_n_generator, generator_n.trainable_variables))\n",
    "    discriminator_t_optimizer.apply_gradients(zip(gradients_of_discriminator_t, discriminator_t.trainable_variables))\n",
    "    discriminator_d_optimizer.apply_gradients(zip(gradients_of_discriminator_d, discriminator_d.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = data.loc[:,('real', 'imag')]\n",
    "train_label = data.loc[:, ('label_real', 'label_imag')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = tf.cast(train_feature, tf.float32)\n",
    "test_label = tf.cast(train_label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....."
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for i in range(len(test_feature)):\n",
    "        test = tf.reshape(test_feature[i], [1,2])\n",
    "        label = tf.reshape(test_label[i], [1,2])\n",
    "        train_step(test, label)\n",
    "        if n % 10 == 0:\n",
    "            print ('.', end='')\n",
    "            n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generator_s(test_feature, training=False)\n",
    "i = generator_i(test_feature, training=False)\n",
    "n = generator_n(test_feature, training=False)\n",
    "gen = s + i + n\n",
    "test = np.array([(test_feature - gen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([s - test_label]).mean()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, input_h\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(20)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50000, 2), dtype=float32, numpy=\n",
       "array([[ 0.74356425, -0.39451778],\n",
       "       [-0.63942367, -0.6913041 ],\n",
       "       [ 0.69628894,  0.9595338 ],\n",
       "       ...,\n",
       "       [-0.59323114, -0.5585426 ],\n",
       "       [-0.6560704 ,  0.2876377 ],\n",
       "       [ 0.56631446,  0.91844213]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_s(train_feature.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = real.size\n",
    "real = np.array([s[:, 0]]).reshape(size)\n",
    "imag = np.array([s[:, 1]]).reshape(size)\n",
    "mlcData = pd.DataFrame({'real':real, 'imag':imag.T, 'label':symbol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"../ML_Symbol_Gen-main/\" + dataFile\n",
    "    labelFile = \"../ML_Symbol_Gen-main/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    mytable = assign_label(myOrig)\n",
    "    return mytable\n",
    "\n",
    "\n",
    "def assign_label(data):\n",
    "    c_4 = [1,-1]\n",
    "    c_16 = [3,1,-1,-3]\n",
    "    c_16r = [-3,-1,1,3]\n",
    "    cons_4 = np.dot(np.sqrt(0.5),[complex(i,j)for i in c_4 for j in c_4])\n",
    "    cons_16 = np.array([complex(i,j)for j in c_16 for i in c_16r])\n",
    "    cons_16 = cons_16/np.sqrt(np.mean(np.abs(cons_16)**2))\n",
    "    cons4 = data[data.cons==1]\n",
    "    cons4_label = np.array([[cons_4[i-1]]for i in cons4.label])\n",
    "    cons16 = data[data.cons==2]\n",
    "    cons16_label = np.array([[cons_16[i-1]]for i in cons16.label.to_numpy().real.astype(int)])\n",
    "    data[data.cons==2].index\n",
    "    data['buffer'] = 0\n",
    "    data['buffer'] = 0\n",
    "    data.iloc[data[data.cons==1].index, 5] = cons4_label\n",
    "    data.iloc[data[data.cons==2].index, 5] = cons16_label\n",
    "    data['label_real'] = data.buffer.to_numpy().real\n",
    "    data['label_imag'] = data.buffer.to_numpy().imag\n",
    "    myTest = data.copy()\n",
    "    myTest.loc[myTest.cons == 2, 'label'] = myTest.loc[myTest.cons == 2, 'label'] + 4\n",
    "    myTest.label = myTest.label - 1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size, )\n",
    "    cons_array = np.array([[cons[i]] * my_data.shape[0] for i in range(0, block)]).reshape(my_data_size, )\n",
    "    block_array = np.array([([i + 1] * my_data.shape[0]) for i in range(0, block)]).reshape(my_data_size, )\n",
    "    label_array = label.T.reshape(my_data_size, )\n",
    "    test_pd = pd.DataFrame({'real': my_data_div.real, 'imag': my_data_div.imag,\n",
    "                            'cons': cons_array, 'block': block_array,\n",
    "                            'label': label_array})\n",
    "    return test_pd\n",
    "\n",
    "\n",
    "def make_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(2, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((50, 2, 1)))\n",
    "    model.add(layers.Conv2DTranspose(128, (2, 1), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Reshape((50,2)))\n",
    "    return model\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Reshape((50, 2, 1)))\n",
    "    model.add(layers.Conv2D(64, (2, 1), strides=(1, 1), padding='same',\n",
    "                                     input_shape=[1, 50, 2]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def identity_loss(real, fake):\n",
    "    loss = tf.reduce_mean(tf.abs(real - fake))\n",
    "    return LAMBDA * 0.5 * loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(total, label):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        s = generator_s(total, training=True)\n",
    "        n = generator_n(total, training=True)\n",
    "        i = generator_i(total, training=True)\n",
    "        gen = (s + n + i)\n",
    "        gen = tf.reshape(gen, (1,50,2))\n",
    "        fake_t = discriminator_t(gen, training=True)\n",
    "        real_t = discriminator_t(total, training=True)\n",
    "        fake_d = discriminator_d(s, training=True)\n",
    "        real_d = discriminator_d(label, training=True)\n",
    "        gen_loss = generator_loss(fake_t)\n",
    "        gen_s_loss = generator_loss(fake_d)\n",
    "        disc_t_loss = discriminator_loss(real_t, fake_t)\n",
    "        disc_d_loss = discriminator_loss(real_d, fake_d)\n",
    "        identity_s_loss = identity_loss(label, s)\n",
    "        identity_g_loss = identity_loss(total, gen)\n",
    "        identity_total_loss = identity_g_loss + identity_s_loss\n",
    "        total_s_loss = identity_total_loss + 1/2 * gen_loss  + gen_s_loss + identity_s_loss\n",
    "        total_n_loss = identity_total_loss + gen_loss\n",
    "        total_i_loss = identity_total_loss + gen_loss\n",
    "\n",
    "    gradients_of_s_generator = tape.gradient(total_s_loss, generator_s.trainable_variables)\n",
    "    gradients_of_i_generator = tape.gradient(total_i_loss, generator_i.trainable_variables)\n",
    "    gradients_of_n_generator = tape.gradient(total_n_loss, generator_n.trainable_variables)\n",
    "    gradients_of_discriminator_t = tape.gradient(disc_t_loss, discriminator_t.trainable_variables)\n",
    "    gradients_of_discriminator_d = tape.gradient(disc_d_loss, discriminator_d.trainable_variables)\n",
    "    generator_s_optimizer.apply_gradients(zip(gradients_of_s_generator, generator_s.trainable_variables))\n",
    "    generator_i_optimizer.apply_gradients(zip(gradients_of_i_generator, generator_i.trainable_variables))\n",
    "    generator_n_optimizer.apply_gradients(zip(gradients_of_n_generator, generator_n.trainable_variables))\n",
    "    discriminator_t_optimizer.apply_gradients(zip(gradients_of_discriminator_t, discriminator_t.trainable_variables))\n",
    "    discriminator_d_optimizer.apply_gradients(zip(gradients_of_discriminator_d, discriminator_d.trainable_variables))\n",
    "\n",
    "def shuffle_data(my_table):\n",
    "    '''\n",
    "    real_y = (2*my_table.real.min())/(my_table.real.max() - my_table.real.min()) + 1\n",
    "    real_x = (my_table.real.max()) / (1 + real_y)\n",
    "    imag_y = (2*my_table.imag.min())/(my_table.imag.max() - my_table.imag.min()) + 1\n",
    "    imag_x = (my_table.imag.max()) / (1 + imag_y)\n",
    "    my_table.real = (my_table.real / real_x) - real_y\n",
    "    my_table.imag = (my_table.imag/ imag_x) - imag_y\n",
    "    '''\n",
    "    train_feature = data.loc[:, ('real', 'imag')]\n",
    "    train_label = data.loc[:, ('label_real', 'label_imag')]\n",
    "    test_feature = tf.cast(train_feature, tf.float32)\n",
    "    test_label = tf.cast(train_label, tf.float32)\n",
    "    test_feature = tf.reshape(test_feature,(1000,1,50,2))\n",
    "    test_label = tf.reshape(test_label, (1000,1,50,2))\n",
    "    symbol = data.loc[:, 'label']\n",
    "    return test_feature, test_label\n",
    "\n",
    "generator_s = make_generator()\n",
    "generator_n = make_generator()\n",
    "generator_i = make_generator()\n",
    "discriminator_t = make_discriminator_model()\n",
    "discriminator_d = make_discriminator_model()\n",
    "\n",
    "\n",
    "generator_s_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_n_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_i_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_t_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/cnn\"\n",
    "ckpt = tf.train.Checkpoint(generator_s=generator_s,\n",
    "                           generator_n=generator_n,\n",
    "                           generator_i=generator_i,\n",
    "                           discriminator_t=discriminator_t,\n",
    "                           discriminator_d=discriminator_d,\n",
    "                           generator_s_optimizer=generator_s_optimizer,\n",
    "                           generator_n_optimizer=generator_n_optimizer,\n",
    "                           generator_i_optimizer=generator_i_optimizer,\n",
    "                           discriminator_d_optimizer=discriminator_d_optimizer,\n",
    "                           discriminator_t_optimizer=discriminator_t_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "LAMBDA = 10\n",
    "EPOCHS = 50\n",
    "data1 = \"my_data\"\n",
    "data1_label = \"my_labels\"\n",
    "data = dataset(data1, data1_label)\n",
    "file_directory = './result/tes2/'\n",
    "f, l = shuffle_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = generator_i(f[0], training=False)\n",
    "n = generator_n(f[0], training=False)\n",
    "s = generator_s(f[0], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50, 2), dtype=float32, numpy=\n",
       "array([[[-0.01165958,  0.04710186],\n",
       "        [-0.04699365,  0.04541421],\n",
       "        [ 0.0286256 ,  0.11764488],\n",
       "        [ 0.04087699,  0.08862203],\n",
       "        [ 0.02970773,  0.04105288],\n",
       "        [-0.03506368,  0.00696408],\n",
       "        [ 0.04236872,  0.08455611],\n",
       "        [ 0.0341803 ,  0.07166582],\n",
       "        [-0.0529087 ,  0.01400566],\n",
       "        [-0.14058375, -0.09424768],\n",
       "        [ 0.0151098 ,  0.09260677],\n",
       "        [ 0.04741369,  0.05953749],\n",
       "        [-0.1777518 , -0.06442233],\n",
       "        [-0.17516671, -0.11706606],\n",
       "        [-0.06003933, -0.05898825],\n",
       "        [ 0.01646209,  0.07246798],\n",
       "        [ 0.03749654,  0.06943575],\n",
       "        [-0.16360986,  0.04353789],\n",
       "        [ 0.01007734,  0.05163335],\n",
       "        [-0.10028578, -0.0232053 ],\n",
       "        [ 0.01163929,  0.09862007],\n",
       "        [-0.12342912,  0.00427034],\n",
       "        [-0.1600461 , -0.00927445],\n",
       "        [-0.04776413,  0.07008516],\n",
       "        [ 0.02773576,  0.06955869],\n",
       "        [-0.10547085, -0.00927497],\n",
       "        [ 0.00997397,  0.07738324],\n",
       "        [ 0.05829114,  0.11171931],\n",
       "        [-0.03821768,  0.06839689],\n",
       "        [-0.18424316, -0.03057099],\n",
       "        [ 0.00371523, -0.01892659],\n",
       "        [ 0.04908825,  0.03761617],\n",
       "        [-0.12994769, -0.10239467],\n",
       "        [ 0.00373906,  0.0635483 ],\n",
       "        [-0.08720475,  0.05613215],\n",
       "        [ 0.02227315,  0.04443428],\n",
       "        [-0.0925844 ,  0.06575475],\n",
       "        [-0.14893949, -0.09555198],\n",
       "        [-0.04477195,  0.05610795],\n",
       "        [ 0.02580728,  0.06497019],\n",
       "        [-0.11389601,  0.04288847],\n",
       "        [-0.07150535,  0.05099155],\n",
       "        [ 0.01988221,  0.08953626],\n",
       "        [-0.09603102,  0.02165951],\n",
       "        [-0.08007205, -0.005918  ],\n",
       "        [ 0.01933923,  0.03536415],\n",
       "        [-0.12582628, -0.09176184],\n",
       "        [ 0.01074331,  0.05927698],\n",
       "        [-0.18007287, -0.04340991],\n",
       "        [-0.00248978,  0.07709638]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(2, use_bias=False, input_shape=[50,2]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((50, 2, 1)))\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.Reshape((50,2)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_test = make_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50, 2), dtype=float32, numpy=\n",
       "array([[[-4.7518844e-03, -1.4423817e-02],\n",
       "        [-6.0334550e-03, -5.9363381e-03],\n",
       "        [-6.2133595e-03, -9.8154284e-03],\n",
       "        [-3.6675632e-03, -9.9786269e-03],\n",
       "        [ 6.6237049e-03, -9.8263128e-03],\n",
       "        [-1.4844697e-03, -1.2666809e-02],\n",
       "        [-3.0093305e-02,  1.7870571e-02],\n",
       "        [-3.0743811e-02, -3.0736204e-03],\n",
       "        [ 1.3923310e-02, -1.3344743e-03],\n",
       "        [ 1.5177790e-03, -4.9369223e-03],\n",
       "        [-1.8499680e-02, -1.1614773e-02],\n",
       "        [-2.4047339e-02,  1.8808618e-04],\n",
       "        [ 5.1625781e-03, -1.6651477e-03],\n",
       "        [ 9.9959970e-03,  1.6799193e-03],\n",
       "        [-1.8128458e-02,  7.5068274e-03],\n",
       "        [ 1.7495800e-03, -6.4042830e-03],\n",
       "        [-1.2254220e-02, -8.0267177e-04],\n",
       "        [ 5.0711455e-03,  4.6894024e-03],\n",
       "        [ 3.7442453e-03, -1.3466846e-02],\n",
       "        [ 6.6979637e-04,  5.9850411e-03],\n",
       "        [-1.2132203e-02, -1.1426675e-03],\n",
       "        [-1.5352142e-02, -4.7459546e-03],\n",
       "        [ 4.7154925e-03,  1.2678334e-02],\n",
       "        [ 6.4445883e-03,  2.0342943e-04],\n",
       "        [-8.2811574e-03, -5.4595282e-04],\n",
       "        [-2.9145672e-03,  1.4594439e-03],\n",
       "        [-8.1313951e-03, -1.8566033e-02],\n",
       "        [-2.8189417e-02, -1.8122606e-02],\n",
       "        [-2.3630941e-03, -1.4190579e-02],\n",
       "        [ 1.5243972e-03, -1.8669717e-02],\n",
       "        [-3.2637697e-03,  7.0774769e-03],\n",
       "        [-2.0801138e-02, -3.6525941e-03],\n",
       "        [-2.0759804e-02,  5.9723379e-03],\n",
       "        [-1.8223519e-02,  3.6116205e-03],\n",
       "        [ 2.5466862e-03,  5.9397724e-03],\n",
       "        [ 5.1288716e-03, -6.1330288e-03],\n",
       "        [ 1.5079106e-02, -9.6076913e-03],\n",
       "        [-1.0383257e-02,  9.1698989e-03],\n",
       "        [-1.1637948e-02,  8.7743793e-03],\n",
       "        [-6.8564899e-05, -7.2174505e-03],\n",
       "        [ 2.2787254e-03, -6.0980949e-03],\n",
       "        [ 2.7172321e-03, -8.0779977e-03],\n",
       "        [-4.2024823e-03, -9.3691964e-03],\n",
       "        [-2.4870313e-03, -3.3489775e-03],\n",
       "        [ 1.3459975e-02, -8.9253252e-03],\n",
       "        [-7.5582652e-03,  6.4608194e-03],\n",
       "        [-1.0111212e-02,  5.4570278e-03],\n",
       "        [-9.4991205e-03,  1.3174746e-02],\n",
       "        [-1.1807247e-02,  4.2184712e-03],\n",
       "        [ 7.3042139e-04,  9.7565744e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_test(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
