{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"./communication/\" + dataFile\n",
    "    labelFile = \"./communication/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    myTable = assign_labels(myOrig)\n",
    "    return myTable\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size,)\n",
    "    cons_array = np.array([[cons[i]]*my_data.shape[0] for i in range(0,block)]).reshape(my_data_size,)\n",
    "    block_array = np.array([([i+1]*my_data.shape[0])for i in range(0, block)]).reshape(my_data_size,)\n",
    "    label_array = label.T.reshape(my_data_size,)\n",
    "    test_pd = pd.DataFrame({'real':my_data_div.real,'imag':my_data_div.imag,\n",
    "            'cons':cons_array, 'block':block_array,\n",
    "            'label':label_array})\n",
    "    return test_pd\n",
    "\n",
    "def assign_labels(myTable):\n",
    "    myTest = myTable.copy()\n",
    "    myTest.loc[myTest.cons==2, 'label'] = myTest.loc[myTest.cons==2, 'label']+4\n",
    "    myTest.label = myTest.label-1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "from numpy.random import default_rng\n",
    "def training_set(myTable):\n",
    "    block = myTable.shape[0]\n",
    "    rng = default_rng()\n",
    "    sample_size = int(0.8 * block)\n",
    "    numbers = rng.choice(range(1, block + 1), size=sample_size, replace=False)\n",
    "    training_dataset = myTable[myTable.block.isin(numbers)]\n",
    "    return training_dataset\n",
    "\n",
    "def test_set(myTable, training_dataset):\n",
    "    remaining = myTable.drop(training_dataset.index)\n",
    "    return remaining\n",
    "\n",
    "\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(20)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_total_loss(predict_label, true_label):\n",
    "    i = 0\n",
    "    for j in range(len(predict_label)):\n",
    "        prediction = np.argmax(predict_label[j])\n",
    "        if prediction != true_label[j]:\n",
    "            i = i + 1\n",
    "    return i/len(predict_label)\n",
    "\n",
    "datas = \"INR30data\"\n",
    "labels = \"INR30labels\"\n",
    "\n",
    "\n",
    "def get_training(myTable, epochs, files):\n",
    "    train_dataset = training_set(myTable)\n",
    "    test_dataset = test_set(myTable, train_dataset)\n",
    "    train_features = train_dataset.copy()\n",
    "    test_features = test_dataset.copy()\n",
    "    train_labels = pd.DataFrame([train_features.pop('label')]).T\n",
    "    test_labels = pd.DataFrame([test_features.pop('label')]).T\n",
    "    normalizer = preprocessing.Normalization()\n",
    "    normalizer.adapt(np.array(train_features))\n",
    "    dnn_real_model = build_and_compile_model(normalizer)\n",
    "    history = dnn_real_model.fit(\n",
    "        train_features, train_labels,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    test_results = {}\n",
    "    test_results['signal'] = dnn_real_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "    probability_model = tf.keras.Sequential([dnn_real_model, \n",
    "                                             tf.keras.layers.Softmax()])\n",
    "    predictions = probability_model.predict(test_features)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist.tail()\n",
    "    loss = get_total_loss(predictions, test_labels.to_numpy())\n",
    "    hist = hist.append(test_results, ignore_index=True)\n",
    "    hist.to_csv('./results/'+ files + '.csv' , index=False)\n",
    "    return dnn_real_model\n",
    "\n",
    "\n",
    "def prediction(model, predictionDataSet, predictionLabels):\n",
    "    test_dataset = dataset(predictionDataSet, predictionLabels)\n",
    "    test_features = test_dataset.copy()\n",
    "    test_labels = pd.DataFrame([test_features.pop('label')]).T\n",
    "    predictions = model.predict(test_features)\n",
    "    test_results = {}\n",
    "    test_results['signal'] = model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "    return test_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Ireal]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 457us/step - loss: 0.3684 - accuracy: 0.7798\n"
     ]
    }
   ],
   "source": [
    "results = dnn_real_model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTable = dataset(\"INR30data\", \"INR30labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = \"INR30data\"\n",
    "labels = \"INR30labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2008/2008 [==============================] - 1s 736us/step - loss: 0.6240 - accuracy: 0.7814 - val_loss: 0.1111 - val_accuracy: 0.9873\n",
      "Epoch 2/10\n",
      "2008/2008 [==============================] - 1s 689us/step - loss: 0.4083 - accuracy: 0.8208 - val_loss: 0.0967 - val_accuracy: 0.9681\n",
      "Epoch 3/10\n",
      "2008/2008 [==============================] - 1s 658us/step - loss: 0.2922 - accuracy: 0.8633 - val_loss: 0.0228 - val_accuracy: 0.9937\n",
      "Epoch 4/10\n",
      "2008/2008 [==============================] - 1s 660us/step - loss: 0.2413 - accuracy: 0.8838 - val_loss: 0.0248 - val_accuracy: 0.9905\n",
      "Epoch 5/10\n",
      "2008/2008 [==============================] - 1s 654us/step - loss: 0.2184 - accuracy: 0.8918 - val_loss: 0.0670 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "2008/2008 [==============================] - 1s 663us/step - loss: 0.2127 - accuracy: 0.8958 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "2008/2008 [==============================] - 1s 691us/step - loss: 0.2051 - accuracy: 0.8988 - val_loss: 0.0294 - val_accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "2008/2008 [==============================] - 1s 662us/step - loss: 0.1959 - accuracy: 0.9024 - val_loss: 0.0298 - val_accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "2008/2008 [==============================] - 1s 655us/step - loss: 0.1958 - accuracy: 0.9026 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "2008/2008 [==============================] - 1s 657us/step - loss: 0.1955 - accuracy: 0.9023 - val_loss: 0.0056 - val_accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model = get_training(new_test, 10, \"new_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotherTable = dataset(\"my_data\", \"my_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal': [0.2934909462928772, 0.8456000089645386]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"INR30data\", \"INR30labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.concat([myTable,anotherTable], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-75-325436e253a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-325436e253a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (a+\"b\") = 1\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "(a+\"b\") = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Bob.\n",
      "What's your name?\n"
     ]
    }
   ],
   "source": [
    "   print(\"I'm Bob.\\nWhat's your name?\") a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
