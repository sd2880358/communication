{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "def dataset(dataFile, labelFile):\n",
    "    dataFile = \"./communication/\" + dataFile\n",
    "    labelFile = \"./communication/\" + labelFile\n",
    "    my_data = sc.loadmat(dataFile)\n",
    "    my_labels = sc.loadmat(labelFile)\n",
    "    my_data = my_data['Y']\n",
    "    X = my_labels['L_S_x']\n",
    "    myOrig = table_data(my_data, my_labels['L_Constellations'][0], X)\n",
    "    myTable = assign_labels(myOrig)\n",
    "    return myTable\n",
    "\n",
    "def table_data(my_data, cons, label):\n",
    "    block = my_data.shape[1]\n",
    "    my_data_size = my_data.shape[0] * block\n",
    "    my_data_div = my_data.T.reshape(my_data_size,)\n",
    "    cons_array = np.array([[cons[i]]*my_data.shape[0] for i in range(0,block)]).reshape(my_data_size,)\n",
    "    block_array = np.array([([i+1]*my_data.shape[0])for i in range(0, block)]).reshape(my_data_size,)\n",
    "    label_array = label.T.reshape(my_data_size,)\n",
    "    test_pd = pd.DataFrame({'real':my_data_div.real,'imag':my_data_div.imag,\n",
    "            'cons':cons_array, 'block':block_array,\n",
    "            'label':label_array})\n",
    "    return test_pd\n",
    "\n",
    "def assign_labels(myTable):\n",
    "    myTest = myTable.copy()\n",
    "    myTest.loc[myTest.cons==2, 'label'] = myTest.loc[myTest.cons==2, 'label']+4\n",
    "    myTest.label = myTest.label-1\n",
    "    return myTest\n",
    "\n",
    "\n",
    "from numpy.random import default_rng\n",
    "def training_set(myTable):\n",
    "    block = myTable.shape[0]\n",
    "    rng = default_rng()\n",
    "    sample_size = int(0.8 * block)\n",
    "    numbers = rng.choice(range(1, block + 1), size=sample_size, replace=False)\n",
    "    training_dataset = myTable[myTable.block.isin(numbers)]\n",
    "    return training_dataset\n",
    "\n",
    "def test_set(myTable, training_dataset):\n",
    "    remaining = myTable.drop(training_dataset.index)\n",
    "    return remaining\n",
    "\n",
    "\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(20)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_total_loss(predict_label, true_label):\n",
    "    i = 0\n",
    "    for j in range(len(predict_label)):\n",
    "        prediction = np.argmax(predict_label[j])\n",
    "        if prediction != true_label[j]:\n",
    "            i = i + 1\n",
    "    return i/len(predict_label)\n",
    "\n",
    "datas = \"INR30data\"\n",
    "labels = \"INR30labels\"\n",
    "\n",
    "\n",
    "def get_training(myTable, epochs, files):\n",
    "    train_dataset = training_set(myTable)\n",
    "    test_dataset = test_set(myTable, train_dataset)\n",
    "    train_features = train_dataset.copy()\n",
    "    test_features = test_dataset.copy()\n",
    "    train_labels = pd.DataFrame([train_features.pop('label')]).T\n",
    "    test_labels = pd.DataFrame([test_features.pop('label')]).T\n",
    "    normalizer = preprocessing.Normalization()\n",
    "    normalizer.adapt(np.array(train_features))\n",
    "    dnn_real_model = build_and_compile_model(normalizer)\n",
    "    history = dnn_real_model.fit(\n",
    "        train_features, train_labels,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    test_results = {}\n",
    "    test_results['signal'] = dnn_real_model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "    probability_model = tf.keras.Sequential([dnn_real_model, \n",
    "                                             tf.keras.layers.Softmax()])\n",
    "    predictions = probability_model.predict(test_features)\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist.tail()\n",
    "    loss = get_total_loss(predictions, test_labels.to_numpy())\n",
    "    hist = hist.append(test_results, ignore_index=True)\n",
    "    print(test_results)\n",
    "    return dnn_real_model\n",
    "\n",
    "\n",
    "def prediction(model, predictionDataSet, predictionLabels):\n",
    "    test_dataset = dataset(predictionDataSet, predictionLabels)\n",
    "    test_features = test_dataset.copy()\n",
    "    test_labels = pd.DataFrame([test_features.pop('label')]).T\n",
    "    predictions = model.predict(test_features)\n",
    "    test_results = {}\n",
    "    test_results['signal'] = model.evaluate(\n",
    "    test_features,\n",
    "    test_labels, verbose=0)\n",
    "    return test_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Ireal]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dnn_real_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7809aac25f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_real_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dnn_real_model' is not defined"
     ]
    }
   ],
   "source": [
    "results = dnn_real_model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTable = dataset(\"INR30data\", \"INR30labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = \"INR30data\"\n",
    "labels = \"INR30labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1015/1015 [==============================] - 1s 729us/step - loss: 0.9204 - accuracy: 0.6714 - val_loss: 0.6973 - val_accuracy: 0.7064\n",
      "Epoch 2/10\n",
      "1015/1015 [==============================] - 1s 625us/step - loss: 0.5775 - accuracy: 0.7428 - val_loss: 0.4945 - val_accuracy: 0.7695\n",
      "Epoch 3/10\n",
      "1015/1015 [==============================] - 1s 627us/step - loss: 0.4512 - accuracy: 0.7856 - val_loss: 0.3872 - val_accuracy: 0.8234\n",
      "Epoch 4/10\n",
      "1015/1015 [==============================] - 1s 645us/step - loss: 0.3761 - accuracy: 0.8164 - val_loss: 0.4031 - val_accuracy: 0.8143\n",
      "Epoch 5/10\n",
      "1015/1015 [==============================] - 1s 629us/step - loss: 0.3437 - accuracy: 0.8296 - val_loss: 0.3945 - val_accuracy: 0.8143\n",
      "Epoch 6/10\n",
      "1015/1015 [==============================] - 1s 629us/step - loss: 0.3253 - accuracy: 0.8378 - val_loss: 0.3913 - val_accuracy: 0.8252\n",
      "Epoch 7/10\n",
      "1015/1015 [==============================] - 1s 644us/step - loss: 0.3115 - accuracy: 0.8416 - val_loss: 0.2975 - val_accuracy: 0.8454\n",
      "Epoch 8/10\n",
      "1015/1015 [==============================] - 1s 630us/step - loss: 0.2952 - accuracy: 0.8507 - val_loss: 0.4071 - val_accuracy: 0.8070\n",
      "Epoch 9/10\n",
      "1015/1015 [==============================] - 1s 627us/step - loss: 0.2865 - accuracy: 0.8492 - val_loss: 0.2749 - val_accuracy: 0.8562\n",
      "Epoch 10/10\n",
      "1015/1015 [==============================] - 1s 630us/step - loss: 0.2864 - accuracy: 0.8529 - val_loss: 0.2784 - val_accuracy: 0.8608\n",
      "{'signal': [0.3043360114097595, 0.8314893841743469]}\n"
     ]
    }
   ],
   "source": [
    "model = get_training(myTable, 10, \"new_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotherTable = dataset(\"my_data\", \"my_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal': [0.2934909462928772, 0.8456000089645386]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \"INR30data\", \"INR30labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.concat([myTable,anotherTable], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-75-325436e253a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-325436e253a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (a+\"b\") = 1\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "(a+\"b\") = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {'signal': [0.2934909462928772, 0.8456000089645386]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal [0.2934909462928772, 0.8456000089645386]\n"
     ]
    }
   ],
   "source": [
    "print(\"signal\", test_results['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.293491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.845600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     signal\n",
       "0  0.293491\n",
       "1  0.845600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
